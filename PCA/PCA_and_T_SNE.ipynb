{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA and T-SNE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santosh2994/AAIC/blob/master/PCA/PCA_and_T_SNE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xRj-iblEQGi8"
      },
      "cell_type": "markdown",
      "source": [
        "# Load MNIST Data "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wp-ij13HQGi-",
        "outputId": "2e95144d-2afb-440d-880b-9ae0dfa04203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        }
      },
      "cell_type": "code",
      "source": [
        "# MNIST dataset downloaded from Kaggle : \n",
        "#https://www.kaggle.com/c/digit-recognizer/data\n",
        "\n",
        "# Functions to read and show images.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "   \n",
        "d0 = pd.read_csv('../data/pca/train.csv')\n",
        "\n",
        "print(d0.head(5)) # print first five rows of d0.\n",
        "\n",
        "# save the labels into a variable l.\n",
        "l = d0['label']\n",
        "\n",
        "# Drop the label feature and store the pixel data in d.\n",
        "d = d0.drop(\"label\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-11e5a46d5fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0md0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/pca/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print first five rows of d0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../data/pca/train.csv' does not exist"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TTAYdlDqQGjE",
        "outputId": "9a674861-05a6-4aaa-bb46-51b203523d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "cell_type": "code",
      "source": [
        "print(d.shape)\n",
        "print(l.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c21fc1e7eb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OFPxxtvlQGjJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# display or plot a number.\n",
        "plt.figure(figsize=(7,7))\n",
        "idx = 1\n",
        "\n",
        "grid_data = d.iloc[idx].as_matrix().reshape(28,28)  # reshape from 1d to 2d pixel array\n",
        "plt.imshow(grid_data, interpolation = \"none\", cmap = \"gray\")\n",
        "plt.show()\n",
        "\n",
        "print(l[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uF4ViytmQGjO"
      },
      "cell_type": "markdown",
      "source": [
        "#  2D Visualization using PCA "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6RWnz578QGjP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pick first 15K data-points to work on for time-effeciency.\n",
        "#Excercise: Perform the same analysis on all of 42K data-points.\n",
        "\n",
        "labels = l.head(42000)\n",
        "data = d.head(42000)\n",
        "\n",
        "print(\"the shape of sample data = \", data.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9qWXuMacQGjU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data-preprocessing: Standardizing the data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "standardized_data = StandardScaler().fit_transform(data)\n",
        "print(standardized_data.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ho9hboDkQGjb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#find the co-variance matrix which is : A^T * A\n",
        "sample_data = standardized_data\n",
        "\n",
        "# matrix multiplication using numpy\n",
        "covar_matrix = np.matmul(sample_data.T , sample_data)\n",
        "\n",
        "print ( \"The shape of variance matrix = \", covar_matrix.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mtlKyc-9QGjg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# finding the top two eigen-values and corresponding eigen-vectors \n",
        "# for projecting onto a 2-Dim space.\n",
        "\n",
        "from scipy.linalg import eigh \n",
        "\n",
        "# the parameter 'eigvals' is defined (low value to heigh value) \n",
        "# eigh function will return the eigen values in asending order\n",
        "# this code generates only the top 2 (782 and 783) eigenvalues.\n",
        "values, vectors = eigh(covar_matrix, eigvals=(782,783))\n",
        "\n",
        "print(\"Shape of eigen vectors = \",vectors.shape)\n",
        "# converting the eigen vectors into (2,d) shape for easyness of further computations\n",
        "vectors = vectors.T\n",
        "\n",
        "print(\"Updated shape of eigen vectors = \",vectors.shape)\n",
        "# here the vectors[1] represent the eigen vector corresponding 1st principal eigen vector\n",
        "# here the vectors[0] represent the eigen vector corresponding 2nd principal eigen vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zfQYzUaKQGjl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# projecting the original data sample on the plane \n",
        "#formed by two principal eigen vectors by vector-vector multiplication.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "new_coordinates = np.matmul(vectors, sample_data.T)\n",
        "\n",
        "print (\" resultanat new data points' shape \", vectors.shape, \"X\", sample_data.T.shape,\" = \", new_coordinates.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q_5hc304QGjp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# appending label to the 2d projected data\n",
        "new_coordinates = np.vstack((new_coordinates, labels)).T\n",
        "\n",
        "# creating a new data frame for ploting the labeled points.\n",
        "dataframe = pd.DataFrame(data=new_coordinates, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\n",
        "print(dataframe.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fGQ6V_LiQGjs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ploting the 2d data points with seaborn\n",
        "import seaborn as sn\n",
        "sn.FacetGrid(dataframe, hue=\"label\", size=10).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "g88y_UkgQGjw"
      },
      "cell_type": "markdown",
      "source": [
        "# PCA using Scikit-Learn"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2Od_a_6uQGjx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initializing the pca\n",
        "from sklearn import decomposition\n",
        "pca = decomposition.PCA()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L_Y6hEhEQGjy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# configuring the parameteres\n",
        "# the number of components = 2\n",
        "pca.n_components = 2\n",
        "pca_data = pca.fit_transform(sample_data)\n",
        "\n",
        "# pca_reduced will contain the 2-d projects of simple data\n",
        "print(\"shape of pca_reduced.shape = \", pca_data.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tISf8ZwJQGj1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# attaching the label for each 2-d data point \n",
        "pca_data = np.vstack((pca_data.T, labels)).T\n",
        "\n",
        "# creating a new data fram which help us in ploting the result data\n",
        "pca_df = pd.DataFrame(data=pca_data, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\n",
        "sn.FacetGrid(pca_df, hue=\"label\", size=6).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WfyEnV8-QGj4"
      },
      "cell_type": "markdown",
      "source": [
        "# PCA for dimensionality redcution (not for visualization)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d8blOjJYQGj5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PCA for dimensionality redcution (non-visualization)\n",
        "\n",
        "pca.n_components = 784\n",
        "pca_data = pca.fit_transform(sample_data)\n",
        "\n",
        "percentage_var_explained = pca.explained_variance_ / np.sum(pca.explained_variance_);\n",
        "\n",
        "cum_var_explained = np.cumsum(percentage_var_explained)\n",
        "\n",
        "# Plot the PCA spectrum\n",
        "plt.figure(1, figsize=(10, 6))\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(cum_var_explained, linewidth=2)\n",
        "plt.axis('tight')\n",
        "plt.grid()\n",
        "plt.xlabel('n_components')\n",
        "plt.ylabel('Cumulative_explained_variance')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# If we take 200-dimensions, approx. 90% of variance is expalined."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pTaRTugBQGj7"
      },
      "cell_type": "markdown",
      "source": [
        "# t-SNE using Scikit-Learn"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bd2bHAybQGj8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TSNE\n",
        "#PErplexity(imp) : it can be called as roughly or loosely the number of neighbours/points \n",
        "\"\"\"\n",
        "it can be defined as the number of the nearest points that are closely related to a particular proximity.\n",
        "this is also called as the loosely coupled data.\n",
        "which helps us in getting from d-dimensions to d' dimensions\n",
        "https://distill.pub/2016/misread-tsne\n",
        "please refer to the above blog for much more information\n",
        "\n",
        "perplexity range can be taken from 5-50 that is the desired values.\n",
        "\n",
        "as perplexity increases our model gets much more defined properly or well separated.\n",
        "low perplexity cannot define a good model , too high perplexity also doesnt help us well.\n",
        "see the shapes that are more stable.\n",
        "\n",
        "never run T-SNE only once.\n",
        "\n",
        "use scikit learn library.\n",
        "\n",
        "never put perplexity equal to the number of points - there it does a terible job.\n",
        "\n",
        "T_SNE:\n",
        "expands dense clusters(dense - closely clustered)\n",
        "contrasts sparse clusters(sparse - farley separated/ large cluster)\n",
        "\n",
        "T-SNE doesnt preserve distances between clusters refer to the above blog.\n",
        "\n",
        "never run your T-SNE once.\n",
        "\n",
        "Epsilon is an optimization technique which we will be using later.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from fastTSNE import TSNE\n",
        "\n",
        "# Picking the top 1000 points as TSNE takes a lot of time for 15K points\n",
        "data_1000 = standardized_data[0:10000,:]\n",
        "labels_1000 = labels[0:10000]\n",
        "\n",
        "model = TSNE(n_components=2,perplexity=30,learning_rate=200)\n",
        "# configuring the parameteres\n",
        "# the number of components = 2\n",
        "# default perplexity = 30\n",
        "# default learning rate = 200\n",
        "# default Maximum number of iterations for the optimization = 1000\n",
        "\n",
        "tsne_data = model.fit(data_1000)\n",
        "\n",
        "\n",
        "# creating a new data frame which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, labels_1000)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sn.FacetGrid(tsne_df, hue=\"label\", height=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "plt.title(\"TSNE for MNIST dataset with data size of 15k\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C-jgsYj8QGj_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = TSNE(n_components=2, random_state=0, perplexity=50)\n",
        "tsne_data = model.fit(data_1000) #in fasttsne it is fit not fit_transform\n",
        "\n",
        "# creating a new data fram which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, labels_1000)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sn.FacetGrid(tsne_df, hue=\"label\", height=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "plt.title('With perplexity = 50')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pCQ460syQGkC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = TSNE(n_components=2, random_state=0, perplexity=50,  n_iter=5000)\n",
        "tsne_data = model.fit(data_1000) \n",
        "\n",
        "# creating a new data fram which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, labels_1000)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sn.FacetGrid(tsne_df, hue=\"label\", height=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "plt.title('With perplexity = 50, n_iter=5000')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BkcpBB1MQGkF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = TSNE(n_components=2, random_state=0, perplexity=2)\n",
        "tsne_data = model.fit(data_1000) \n",
        "\n",
        "# creating a new data fram which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, labels_1000)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sn.FacetGrid(tsne_df, hue=\"label\", height=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "plt.title('With perplexity = 2 and working on a dataset of size 10k')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QvMINUG_QGkH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Excercise: Run the same analysis using 42K points with various \n",
        "#values of perplexity and iterations.\n",
        "\n",
        "# If you use all of the points, you can expect plots like this blog below:\n",
        "# http://colah.github.io/posts/2014-10-Visualizing-MNIST/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L6T6jHFXQGkK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}